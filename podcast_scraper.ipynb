{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add User agent to scrape the site\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "opts = Options()\n",
    "opts.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "cfg = ConfigParser(interpolation=None) \n",
    "cfg.read('conf.ini')\n",
    "login_conf = cfg['chartable']\n",
    "user_email = login_conf['email'] \n",
    "passwd = login_conf['passwd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Login to Chartable\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(options=opts)\n",
    "driver.get('https://www.chartable.com/sign_in')\n",
    "\n",
    "email = driver.find_element_by_id('Email')\n",
    "\n",
    "password = driver.find_element_by_id('Password')\n",
    "\n",
    "email.send_keys(user_email)\n",
    "password.send_keys(passwd)\n",
    "\n",
    "driver.find_element_by_name('commit').click()\n",
    "time.sleep(5)\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get desired podcast ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_podcast_ranks(num_ranks, platform):    \n",
    "    platform = platform.lower()\n",
    "    \n",
    "    if not isinstance(num_ranks,int):\n",
    "        raise TypeError('Rank number must be an integer')\n",
    "    \n",
    "    elif num_ranks >250 and platform=='apple':\n",
    "        raise ValueError('Rank number exceeds Apple chart: select number <=250.')\n",
    "    elif num_ranks >200 and platform == 'spotify':\n",
    "        raise ValueError('Rank number exceeds Spotify chart: select number <=200.')\n",
    "    elif platform not in ['apple','spotify']:\n",
    "        raise ValueError('Platform must be either: apple or spotify')\n",
    "    driver = webdriver.Chrome(options=opts)\n",
    "\n",
    "    driver.get('https://www.chartable.com/sign_in')\n",
    "\n",
    "    email = driver.find_element_by_id('Email')\n",
    "\n",
    "    password = driver.find_element_by_id('Password')\n",
    "\n",
    "    email.send_keys(user_email)\n",
    "    password.send_keys(passwd)\n",
    "\n",
    "    driver.find_element_by_name('commit').click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Start .csv file for top 50 chart\n",
    " \n",
    "    if platform == 'apple':\n",
    "        chart_url = 'https://www.chartable.com/charts/itunes/us-all-podcasts-podcasts'\n",
    "        filename = f'apple_{num_ranks}_ranks.csv'\n",
    "        if num_ranks<=100:\n",
    "            num_pages = 1\n",
    "        else:\n",
    "            num_pages = num_ranks//100+1\n",
    "            \n",
    "    elif platform == 'spotify':\n",
    "        chart_url = 'https://chartable.com/charts/spotify/united-states-of-america-top-podcasts'\n",
    "        filename = f'spotify_{num_ranks}_ranks.csv' \n",
    "        if num_ranks <=50:\n",
    "            num_pages = 1\n",
    "        else:\n",
    "            num_pages = num_ranks//50+1\n",
    "    \n",
    "    \n",
    "    csv_chart_file = open(filename, 'w', encoding='utf-8', newline='')\n",
    "    chart_writer = csv.writer(csv_chart_file)\n",
    "\n",
    "    #Open Google Chrome bot\n",
    "    \n",
    "\n",
    "    #Get ranks of all on the page\n",
    "    page_index = 0\n",
    "    while page_index< num_pages: \n",
    "        try:\n",
    "            print(f'Scraping page {page_index+1}...')\n",
    "            \n",
    "            driver.get(chart_url)\n",
    "            ranks_elems = driver.find_elements_by_xpath('//div[@class = \"b header-font f2 tc\"]')\n",
    "            ranks = [int(rank.text) for rank in ranks_elems]\n",
    "            rows = driver.find_elements_by_xpath('//td[@class = \"pv2 ph1\"]')\n",
    "            for row in rows:\n",
    "                podcast_dict = {}\n",
    "                try:\n",
    "                    podcast_url = row.find_element_by_xpath('./div[@class = \"title f3\"]/a').get_attribute('href')\n",
    "                except:\n",
    "                    ranks.pop(0)\n",
    "                    continue\n",
    "                if row.text.find('\\n') ==-1:\n",
    "                    name = row.text\n",
    "                    network = 'Unaffiliated'\n",
    "                else:\n",
    "                    network, name= row.text.split('\\n')\n",
    "\n",
    "                podcast_dict['rank']=ranks.pop(0)\n",
    "                podcast_dict['name'] = name\n",
    "                podcast_dict['network'] = network\n",
    "                podcast_dict['date_scraped'] = date.today().strftime('%Y-%m-%d')\n",
    "                podcast_dict['url'] = podcast_url\n",
    "\n",
    "                chart_writer.writerow(podcast_dict.values())\n",
    "\n",
    "                \n",
    "            \n",
    "            chart_url = driver.find_element_by_xpath('//span[@class = \"next\"]/a').get_attribute('href')\n",
    "            time.sleep(4)\n",
    "            page_index +=1\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    print(f'All {num_ranks} podcasts obtained')\n",
    "    csv_chart_file.close()\n",
    "    driver.close()\n",
    "    \n",
    "    colnames = names = [f'{platform}_rank','name','network','date_scraped','url']\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(filename,names = colnames)\n",
    "    df = df.loc[df[f'{platform}_rank']<=num_ranks]\n",
    "    return df.to_csv(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "All 200 podcasts obtained\n"
     ]
    }
   ],
   "source": [
    "#Get all rankings for spotify, saved as \"spotify_200_ranks.csv\"\n",
    "get_podcast_ranks(200,'spotify')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "All 250 podcasts obtained\n"
     ]
    }
   ],
   "source": [
    "#Get all rankings for apple, saved as \"apple_250_ranks.csv\"\n",
    "get_podcast_ranks(250,'apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "All 100 podcasts obtained\n"
     ]
    }
   ],
   "source": [
    "get_podcast_ranks(100,'spotify')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping episode info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://chartable.com/podcasts/the-joe-rogan-e...\n",
       "1             https://chartable.com/podcasts/the-daily\n",
       "2          https://chartable.com/podcasts/crime-junkie\n",
       "3          https://chartable.com/podcasts/npr-news-now\n",
       "4              https://chartable.com/podcasts/up-first\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top100['url'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_podcast_info(filename):\n",
    "    driver = webdriver.Chrome(options=opts)\n",
    "    driver.get('https://www.chartable.com/sign_in')\n",
    "\n",
    "    email = driver.find_element_by_id('Email')\n",
    "\n",
    "    password = driver.find_element_by_id('Password')\n",
    "\n",
    "    email.send_keys(user_email)\n",
    "    password.send_keys(passwd)\n",
    "\n",
    "    driver.find_element_by_name('commit').click()\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        chart_file = pd.read_csv(filename)\n",
    "    except:\n",
    "        raise ValueError(r'File cannot be found: please use a valid file (example: \"spotify_100_ranks.csv\")')\n",
    "\n",
    "    csv_podcast_file = open('podcast_data.csv', 'w', encoding='utf-8', newline='') \n",
    "    podcast_writer = csv.writer(csv_podcast_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Transfer to the podcast page\n",
    "    for url in chart100['url']:\n",
    "        driver.get(url)\n",
    "\n",
    "        try:\n",
    "            find_genre = driver.find_elements_by_xpath('//div[@class = \"links bg-white pa3 br2 b--near-white ba f6\"]//div/a[contains(@href,\"genre\")]')\n",
    "            try:\n",
    "                genre = find_genre.text\n",
    "            except:\n",
    "                genre = [i.text for i in find_genre]\n",
    "        except:\n",
    "            genre = 'Unknown'\n",
    "\n",
    "        try:\n",
    "            stars_ratings = driver.find_element_by_xpath('//div[@class = \"gray\"]').text\n",
    "            stars, ratings = stars_ratings.split(' stars from ')\n",
    "            try:\n",
    "                ratings = int(ratings.replace(',','').replace('ratings',''))\n",
    "            except:\n",
    "                ratings = int(ratings.replace('ratings',''))\n",
    "        except:\n",
    "            stars = None\n",
    "            ratings = None\n",
    "\n",
    "        podcast_dict = {}\n",
    "\n",
    "        podcast_dict['genre'] = genre\n",
    "        podcast_dict['stars'] = stars\n",
    "        podcast_dict['ratings'] = ratings\n",
    "        podcast_dict['url'] = url\n",
    "\n",
    "\n",
    "\n",
    "        episodes_url = driver.find_element_by_xpath('//div[@class = \"link mb2\"]/a').get_attribute('href')\n",
    "        time.sleep(4)\n",
    "        driver.get(episodes_url)\n",
    "\n",
    "\n",
    "\n",
    "        index = 1\n",
    "        while True:\n",
    "            try:\n",
    "                wait_episodes = WebDriverWait(driver, 10)\n",
    "                episodes = wait_episodes.until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class = \"mb4\"]')))\n",
    "                for episode in episodes:\n",
    "                    episode_info = episode.find_elements_by_xpath('.//div')\n",
    "                    episode_info = [i.text for i in episode_info]\n",
    "                    if episode_info:\n",
    "                        episode_date = episode_info.pop()\n",
    "                    else:\n",
    "                        continue\n",
    "                    podcast_dict['episode_date'] = episode_date.replace('Published ','')\n",
    "\n",
    "                    podcast_writer.writerow(podcast_dict.values())   \n",
    "                next_episodes_link = driver.find_element_by_xpath('//span[@class = \"next\"]/a').get_attribute('href')\n",
    "                time.sleep(4)\n",
    "                driver.get(next_episodes_link)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    csv_podcast_file.close()\n",
    "    driver.close()\n",
    "    print('All episode information scraped!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run line below if error leaves csv/driver open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     csv_file.close()\n",
    "#     driver.close()\n",
    "# except:\n",
    "#     driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_podcast_info('spotify_100_ranks.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
